library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
#Required Data files
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/")
#Load Sample Info
Sample.Info <- read.csv(file="Data/SDR_data/REFERENCE_number.individuals_shell.size.csv", header=T) #read sample.info data
# X = the cumulative summary table of all Lolin outputs
# (1) merge witht he individual number or size data after you make the cumulative table
#x <- merge(df_total, Sample.Info, by=c("Date","SDR_position", "RUN")) # merge the individual info (size, estimate number of larvae) by common columns
# (2) instead of making this table (renders through many csv files for hours) - open the csv of the finished table itself
# call the cumulative resp table of Lolin raw outputs
cumulative_resp_table <- read.csv(file="Data/SDR_data/Cumulative_resp_alpha0.4.csv", header=T) #read sample.info data
# call the sample info of size and number of individuals per trial ( sample info called above)
x <- merge(cumulative_resp_table, Sample.Info, by=c("Date","SDR_position", "RUN"))
x
# analysis of juvenile resp 150d post summer experiments
JUVresp_all <- x %>%
filter((substr(x$Notes, 1,9)) == "juveniles") # call only resp values of juveniles
JUVresp_all
# analysis of juvenile resp 150d post summer experiments
JUVresp_all <- x %>%
filter((substr(x$Notes, 1,9)) == "juveniles") # call only resp values of juveniles
JUVresp_blanks <- JUVresp_all %>%  filter(JUVresp_all$Tank.ID == "Blank") # call only blanks
JUVresp_blankMEANS <- JUVresp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
JUVresp_geoduck <- JUVresp_all %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
JUVresp_geoduck$Resp_rate_ug.mol <-
((((((abs(JUVresp_geoduck$Lpc)) - (JUVresp_blankMEANS$mean_Lpc))*(4/1000))*(60))*31.998)/(JUVresp_geoduck$length_number.individuals))
JUVresp_geoduck$Resp_rate_ug.mol
# RESPIRATION SUMMARY TABLE
JUVresp_table_treatments_ALL <- JUVresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
JUVresp_table_treatments_ALL # view table
rlang
rlang::last_error()
UVresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol)
JUVresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol))
JUVresp_geoduck
# RESPIRATION SUMMARY TABLE
JUVresp_table_treatments_ALL <- JUVresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
JUVresp_table_treatments_ALL # view table
# RESP: INITIAL TREATMENT sUMMRAY TABLE
JUVresp_table_treatments_INITIAL <- JUVresp_geoduck %>%
group_by(Treat.initial) %>% #group the dataset by INITIAL TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
JUVresp_table_treatments_INITIAL # view table
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("tidyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('tidyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
library("devtools")
library("segmented")
if ("rlang" %in% rownames(installed.packages()) == 'FALSE') install.packages('rlang')
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("devtools")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
library('rlang')          # Version: 0.3.0.1 Date/Publication: 2018-10-25, Depends: R (>= 3.1.0)
library('tidyr')          # Version: 0.8.1, Date/Publication: 2018-05-18, Depends: R (>= 3.1) Imports: dplyr (>= 0.7.0), glue, magrittr, purrr, Rcpp, rlang, stringi, tibble, tidyselect
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/")
#Load Sample Info
Sample.Info <- read.csv(file="Data/SDR_data/REFERENCE_number.individuals_shell.size.csv", header=T) #read sample.info data
# X = the cumulative summary table of all Lolin outputs
# (1) merge witht he individual number or size data after you make the cumulative table
#x <- merge(df_total, Sample.Info, by=c("Date","SDR_position", "RUN")) # merge the individual info (size, estimate number of larvae) by common columns
# (2) instead of making this table (renders through many csv files for hours) - open the csv of the finished table itself
# call the cumulative resp table of Lolin raw outputs
cumulative_resp_table <- read.csv(file="Data/SDR_data/Cumulative_resp_alpha0.4.csv", header=T) #read sample.info data
# call the sample info of size and number of individuals per trial ( sample info called above)
x <- merge(cumulative_resp_table, Sample.Info, by=c("Date","SDR_position", "RUN"))
# analysis of juvenile resp 150d post summer experiments
JUVresp_all <- x %>%
filter((substr(x$Notes, 1,9)) == "juveniles") # call only resp values of juveniles
JUVresp_blanks <- JUVresp_all %>%  filter(JUVresp_all$Tank.ID == "Blank") # call only blanks
JUVresp_blankMEANS <- JUVresp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
JUVresp_geoduck <- JUVresp_all %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
JUVresp_geoduck$Resp_rate_ug.mol <-
((((((abs(JUVresp_geoduck$Lpc)) - (JUVresp_blankMEANS$mean_Lpc))*(4/1000))*(60))*31.998)/(JUVresp_geoduck$length_number.individuals))
JUVresp_geoduck$Resp_rate_ug.mol
# RESPIRATION SUMMARY TABLE
JUVresp_table_treatments_ALL <- JUVresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
JUVresp_table_treatments_ALL # view table
JUVresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp))
rlang::last_error()
summary(rlang::last_error())
# RESP: INITIAL TREATMENT sUMMRAY TABLE
JUVresp_table_treatments_INITIAL <- JUVresp_geoduck %>%
group_by(Treat.initial) %>% #group the dataset by INITIAL TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
JUVresp_table_treatments_INITIAL # view table
# RESP: SECODNARY TREATMENT SUMMARY TABLE
JUVresp_table_treatments_SECONDARY<- JUVresp_geoduck %>%
group_by(Treat.Secondary) %>% #group the dataset by SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
JUVresp_table_treatments_SECONDARY # view table
# RUN A TWO WAY ANOVA ON INITIAL AND SECONDARY TREATMENT ON RESP
JUVresp.mod  <- aov(Resp_rate_ug.mol~Treat.initial*Treat.Secondary, data = JUVresp_geoduck)
anova(JUVresp.mod)
TukeyHSD(JUVresp.mod) # tukey HSD of the entire model shows a signifcant difference between the E×E and E×A treatments
par(mfrow=c(1,3)) #set plotting configuration
par(mar=c(1,1,1,1)) #set margins for plots
shapiro.test((residuals(JUVresp.mod)))
hist(residuals(JUVresp.mod)) #plot histogram of residuals
boxplot(residuals(JUVresp.mod)) #plot boxplot of residuals
plot(fitted(JUVresp.mod),residuals(JUVresp.mod))
library(Rmisc)
sum_JUVresp_means <- summarySE(JUVresp_geoduck,
measurevar="Resp_rate_ug.mol",
groupvars=c("Treat.Secondary")) # summarize previous table for overall treatment
sum_JUVresp_means # view the table
percentdiff <- ((sum_JUVresp_means[1,3] - sum_JUVresp_means[2,3])/sum_JUVresp_means[1,3])*100 # calculate percent difference
percentdiff # 5.8% greater shell length from animals initally exposed to low pH in initial exp trial
# SHELL SIZE SUMMARY TABLE
JUVsize_table_treatments_ALL <- JUVresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_size = mean(length_number.individuals),
min_size = min(length_number.individuals),
sd_size = sd(length_number.individuals),
SEM = ((sd(length_number.individuals))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_size)) # makes table in descending order
JUVsize_table_treatments_ALL # view table - IMPORTANT - looks like initial exposure exposure has the greatest shell size!
# analysis of LARVAE resp - from 20190131
LARVAEresp_all <- x %>%
filter((substr(x$Date, 1,9)) == "20190131") # call only resp values of juveniles
LARVAEresp_blanks <- LARVAEresp_all %>%  filter(LARVAEresp_all$Tank.ID == "Blank") # call only blanks
LARVAEresp_blankMEANS <- LARVAEresp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
LARVAEresp_geoduck <- LARVAEresp_all %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
LARVAEresp_geoduck$Resp_rate_ug.mol <-
((((((abs(LARVAEresp_geoduck$Lpc)) - (LARVAEresp_blankMEANS$mean_Lpc))*(4/1000))*(60))*31.998)/(LARVAEresp_geoduck$length_number.individuals))
LARVAEresp_geoduck$Resp_rate_ug.mol
# RESPIRATION SUMMARY TABLE
LARVAEresp_table_treatments_ALL <- LARVAEresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
LARVAEresp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("tidyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('tidyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("devtools")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
library('tidyr')          # Version: 0.8.1, Date/Publication: 2018-05-18, Depends: R (>= 3.1) Imports: dplyr (>= 0.7.0), glue, magrittr, purrr, Rcpp, rlang, stringi, tibble, tidyselect
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/")
#Load Sample Info
Sample.Info <- read.csv(file="Data/SDR_data/REFERENCE_number.individuals_shell.size.csv", header=T) #read sample.info data
# X = the cumulative summary table of all Lolin outputs
# (1) merge witht he individual number or size data after you make the cumulative table
#x <- merge(df_total, Sample.Info, by=c("Date","SDR_position", "RUN")) # merge the individual info (size, estimate number of larvae) by common columns
# (2) instead of making this table (renders through many csv files for hours) - open the csv of the finished table itself
# call the cumulative resp table of Lolin raw outputs
cumulative_resp_table <- read.csv(file="Data/SDR_data/Cumulative_resp_alpha0.4.csv", header=T) #read sample.info data
# call the sample info of size and number of individuals per trial ( sample info called above)
x <- merge(cumulative_resp_table, Sample.Info, by=c("Date","SDR_position", "RUN"))
# analysis of LARVAE resp - from 20190131
LARVAEresp_all <- x %>%
filter((substr(x$Date, 1,9)) == "20190131") # call only resp values of juveniles
LARVAEresp_blanks <- LARVAEresp_all %>%  filter(LARVAEresp_all$Tank.ID == "Blank") # call only blanks
LARVAEresp_blankMEANS <- LARVAEresp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
LARVAEresp_geoduck <- LARVAEresp_all %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
LARVAEresp_geoduck$Resp_rate_ug.mol <-
((((((abs(LARVAEresp_geoduck$Lpc)) - (LARVAEresp_blankMEANS$mean_Lpc))*(4/1000))*(60))*31.998)/(LARVAEresp_geoduck$length_number.individuals))
LARVAEresp_geoduck$Resp_rate_ug.mol
# RESPIRATION SUMMARY TABLE
LARVAEresp_table_treatments_ALL <- LARVAEresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
LARVAEresp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
rm(list=ls())
## Install packages if not already in your library
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("ggplot2" %in% rownames(installed.packages()) == 'FALSE') install.packages('ggplot2')
if ("ggpubr" %in% rownames(installed.packages()) == 'FALSE') install_github('ggpubr')
if ("Rmisc" %in% rownames(installed.packages()) == 'FALSE') install.packages('Rmisc')
#if ("nlme" %in% rownames(installed.packages()) == 'FALSE') install.packages('nlme')
#if ("lme4" %in% rownames(installed.packages()) == 'FALSE') install.packages('lme4')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("lsmeans" %in% rownames(installed.packages()) == 'FALSE') install.packages('lsmeans')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("reshape" %in% rownames(installed.packages()) == 'FALSE') install.packages('reshape')
if ("multcompView" %in% rownames(installed.packages()) == 'FALSE') install.packages('multcompView')
if ("tidyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('tidyr')
if ("Rcmdr" %in% rownames(installed.packages()) == 'FALSE') install.packages('Rcmdr')
if ("rlang" %in% rownames(installed.packages()) == 'FALSE') install.packages('rlang')
# Load packages and pacage version/date/import/depends info
library(dplyr)          # Version 0.7.6, Packaged: 2018-06-27, Depends: R (>= 3.1.2)Imports: assertthat (>= 0.2.0), bindrcpp (>= 0.2.0.9000), glue (>=1.1.1), magrittr (>= 1.5), methods, pkgconfig (>= 2.0.1), R6(>= 2.2.2), Rcpp (>= 0.12.15), rlang (>= 0.2.0), tibble (>=1.3.1), tidyselect (>= 0.2.3), utils
library(plyr)           # Version 1.8.4, Packaged: 2016-06-07, Depends: R (>= 3.1.0) Imports: Rcpp (>= 0.11.0)
library(ggplot2)        # Version 3.1.0, Date/Publication: 2018-10-25, Depends: R (>= 3.1)Imports: digest, grid, gtable (>= 0.1.1), lazyeval, MASS, mgcv, plyr(>= 1.7.1), reshape2, rlang (>= 0.2.1), scales (>= 0.5.0),stats, tibble, viridisLite, withr (>= 2.0.0)
library(ggpubr)         # Version: 0.1.8 Date: 2018-08-30, Depends: R (>= 3.1.0), ggplot2, magrittrImports: ggrepel, grid, ggsci, stats, utils, tidyr, purrr, dplyr(>=0.7.1), cowplot, ggsignif, scales, gridExtra, glue, polynom
library(Rmisc)          # Version: 1.5 Packaged: 2013-10-21, Depends: lattice, plyr
#library(nlme)           # Version: 3.1-137, Date: 2018-04-07, Depends: R (>= 3.4.0) Imports: graphics, stats, utils, lattice
#library(lme4)           # Version: 1.1-17, Date/Publication: 2018-04-03, Depends: R (>= 3.2.0), Matrix (>= 1.2-1), methods, stats
library(plotrix)        # Version: 3.7-4, Date/Publication: 2018-10-03
library(lsmeans)        # Version: 2.27-62, Date/Publication: 2018-05-11, Depends: methods, R (>= 3.2)
library(gridExtra)      # Version: 2.3, Date/Publication: 2017-09-09, Imports: gtable, grid, grDevices, graphics, utils
library(reshape)        # Version: 0.8.7, Date/Publication: 2017-08-06, Depends: R (>= 2.6.1) Imports: plyr
library(multcompView)   # Version: 0.1-7, Date/Publication: 2015-07-31, Imports: grid
library(tidyr)          # Version: 0.8.1, Date/Publication: 2018-05-18, Depends: R (>= 3.1) Imports: dplyr (>= 0.7.0), glue, magrittr, purrr, Rcpp, rlang, stringi, tibble, tidyselect
library(Rcmdr)          # Version: 2.5-1. Date/Publication: 2018-09-11, Depends: R (>= 3.5.0), grDevices, graphics, methods, stats, utils,splines, RcmdrMisc (>= 2.5-0), car (>= 3.0-1), effects (>=4.0-3) Imports: tcltk, tcltk2 (>= 1.2-6), abind, relimp (>= 1.0-5)
library(rlang)          # Version: 0.3.0.1 Date/Publication: 2018-10-25, Depends: R (>= 3.1.0)
#set working directory--------------------------------------------------------------------------------------------------
setwd("C:/Users/samjg/Documents/Notebook/data/Geoduck_Conditioning/RAnalysis/") #set working
# Growth
size_150days_postEXP<-read.csv("Data/20190116_shell_size_150d_after_experiment.csv", header=T, sep=",", na.string="NA", as.is=T)
size_150days_postEXP <- na.omit(size_150days_postEXP)
size_150days_postEXP # look at the data
names(size_150days_postEXP) # look at names of data
# both Treat1_Treat2s
size_table_Treat1Treat2 <- do.call(data.frame,aggregate(Length_mm ~ Treat1_Treat2,
data = size_150days_postEXP, function(x) c(mean = mean(x), se = std.error(x))))
size_table_Treat1Treat2 # view the table
# analysis
size_150days_postEXP.aov.mod <- aov(Length_mm ~ Init_treat*Sec_treat, data = size_150days_postEXP) # run anova on Treat1_Treat2 and time
anova(size_150days_postEXP.aov.mod) # significant effect fromboth inital and secondary Treat1_Treat2
# Levene's test for homogeneity
# levene.test(size.aov.mod)
# plot the residuals
par(mfrow=c(1,3)) #set plotting configuration
par(mar=c(1,1,1,1)) #set margins for plots
leveneTest(size_150days_postEXP.aov.mod) # p = 0.4317
hist(residuals(size_150days_postEXP.aov.mod)) #plot histogram of residuals
boxplot(residuals(size_150days_postEXP.aov.mod)) #plot boxplot of residuals
plot(fitted(size_150days_postEXP.aov.mod),residuals(size_150days_postEXP.aov.mod))
sumLENGTH_means.150days <- summarySE(size,
measurevar="Length_mm",
groupvars=c("Init_treat")) # summarize previous table for overall Treat1_Treat2
sumLENGTH_means.150days # view the table
sumLENGTH_means.150days # view the table
percentdiff.150days <- ((sumLENGTH_means.150days[2,3] - sumLENGTH_means.150days[1,3])/sumLENGTH_means.150days[2,3])*100 # calculate percent difference
percentdiff.150days # 5.8% greater shell length from animals initally exposed to low pH in initial exp trial
if ("Rmisc" %in% rownames(installed.packages()) == 'FALSE') install.packages('Rmisc')
sumLENGTH_means.150days <- summarySE(size,
measurevar="Length_mm",
groupvars=c("Init_treat")) # summarize previous table for overall Treat1_Treat2
sumLENGTH_means.150days # view the table
percentdiff.150days <- ((sumLENGTH_means.150days[2,3] - sumLENGTH_means.150days[1,3])/sumLENGTH_means.150days[2,3])*100 # calculate percent difference
percentdiff.150days # 5.8% greater shell length from animals initally exposed to low pH in initial exp trial
# significant effect graph
size_graph_INITIAL.150days <- ggplot(size_150days_postEXP, aes(x = factor(Init_treat), y = Length_mm, fill = Init_treat)) +
theme_classic() +
scale_fill_manual(values=c("white", "grey3"),
labels=c("Ambient", "Elevated")) +
geom_boxplot(alpha = 0.5, # color hue
width=0.6, # boxplot width
outlier.size=0, # make outliers small
position = position_dodge(preserve = "single")) +
geom_point(pch = 19, position = position_jitterdodge(.05), size=1) +
stat_summary(fun.y=mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..),
width = 0.6, size=0.4, linetype = "dashed", position = position_dodge(preserve = "single")) +
theme(legend.position = c(0.55,0.96), legend.direction="horizontal", legend.title=element_blank()) +
ylim(4,13) +
scale_x_discrete(labels = c("Ambient","Elevated")) +
labs(y=expression("Shell size"~(mm)), x=expression("Initial treatment"))
size_graph_INITIAL.150days
#Both treatments from secnondary exposure graph
size_graph_INITIAL.SECOND.150days <- ggplot(size_150days_postEXP, aes(x = factor(Treat1_Treat2), y = Length_mm, fill = Treat1_Treat2)) +
theme_classic() +
scale_fill_manual(values=c("white", "grey80",  "gray50", "grey3"),
labels=c("Ambient × Ambient","Ambient × Elevated","Elevated × Ambient","Elevated × Elevated")) +
geom_boxplot(alpha = 0.5, # color hue
width=0.6, # boxplot width
outlier.size=0, # make outliers small
position = position_dodge(preserve = "single")) +
geom_point(pch = 19, position = position_jitterdodge(.05), size=1) +
stat_summary(fun.y=mean, geom = "errorbar", aes(ymax = ..y.., ymin = ..y..),
width = 0.6, size=0.4, linetype = "dashed", position = position_dodge(preserve = "single")) +
theme(legend.position = c(0.55,0.96), legend.direction="horizontal", legend.title=element_blank()) +
ylim(4,13) +
scale_x_discrete(labels = c("Ambient × Ambient","Ambient × Elevated","Elevated × Ambient","Elevated × Elevated")) +
labs(y=expression("Shell size"~(mm)), x=expression("Initial×Secondary treatment"))
size_graph_INITIAL.SECOND.150days
# Respiration
RESP.reference.resp150days.postEXP<-read.csv("Data/SDR_data/20190116_resp_150d_cumulative_alpha0.4.csv", header=T, sep=",", na.string="NA", as.is=T)
SIZE.reference.resp150days.postEXP<-read.csv("Data/SDR_data/20190116_shellsize_reference.csv", header=T, sep=",", na.string="NA", as.is=T)
RESP.CALC.150.days.postEXP <- merge(RESP.reference.resp150days.postEXP, SIZE.reference.resp150days.postEXP, by=c("Date","SDR_position", "RUN")) # merge the individual info (size, estimate number of larvae) by common columns
RESP.CALC.150.days.postEXP # view new file
names(x)
names(RESP.CALC.150.days.postEXP)
# from visual of Lolin plots - RUN1 C1, C4, and C5 were bad data, non linear and likely an error (air bubble)
x <- RESP.CALC.150.days.postEXP[-c(25,31,33),] # x = Resp data with out these points (stated above)
JUVresp_all <- x %>%
filter((substr(x$Notes, 1,9)) == "juveniles") # call only resp values of juveniles
JUVresp_blanks <- JUVresp_all %>%  filter(JUVresp_all$Tank.ID == "Blank") # call only blanks
JUVresp_blankMEANS <- JUVresp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
JUVresp_geoduck <- JUVresp_all %>%
filter(!is.na(length_number.individuals))
JUVresp_geoduck$Resp_rate_ug.mol <-
((((((abs(JUVresp_geoduck$Lpc)) - (JUVresp_blankMEANS$mean_Lpc))*(4/1000))*(60))*31.998)/(JUVresp_geoduck$length_number.individuals))
JUVresp_geoduck$Resp_rate_ug.mol
JUVresp_table_treatments_ALL <- JUVresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
JUVresp_table_treatments_ALL # view table
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("devtools")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/")
#Load Sample Info
Sample.Info <- read.csv(file="Data/SDR_data/REFERENCE_number.individuals_shell.size.csv", header=T) #read sample.info data
# X = the cumulative summary table of all Lolin outputs
# (1) merge witht he individual number or size data after you make the cumulative table
#x <- merge(df_total, Sample.Info, by=c("Date","SDR_position", "RUN")) # merge the individual info (size, estimate number of larvae) by common columns
# (2) instead of making this table (renders through many csv files for hours) - open the csv of the finished table itself
# call the cumulative resp table of Lolin raw outputs
cumulative_resp_table <- read.csv(file="Data/SDR_data/Cumulative_resp_alpha0.4.csv", header=T) #read sample.info data
# call the sample info of size and number of individuals per trial ( sample info called above)
x <- merge(cumulative_resp_table, Sample.Info, by=c("Date","SDR_position", "RUN"))
# analysis of LARVAE resp - from 20190131
LARVAEresp_all <- x %>%
filter((substr(x$Date, 1,9)) == "20190131") # call only resp values of juveniles
LARVAEresp_blanks <- LARVAEresp_all %>%  filter(LARVAEresp_all$Tank.ID == "Blank") # call only blanks
LARVAEresp_blankMEANS <- LARVAEresp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
LARVAEresp_geoduck <- LARVAEresp_all %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
LARVAEresp_geoduck$Resp_rate_ug.mol <-
((((((abs(LARVAEresp_geoduck$Lpc)) - (LARVAEresp_blankMEANS$mean_Lpc))*(4/1000))*(60))*31.998)/(LARVAEresp_geoduck$length_number.individuals))
LARVAEresp_geoduck$Resp_rate_ug.mol
# RESPIRATION SUMMARY TABLE
LARVAEresp_table_treatments_ALL <- LARVAEresp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
LARVAEresp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
rm(list=ls())
## Install packages if not already in your library
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("ggplot2" %in% rownames(installed.packages()) == 'FALSE') install.packages('ggplot2')
if ("ggpubr" %in% rownames(installed.packages()) == 'FALSE') install_github('ggpubr')
if ("Rmisc" %in% rownames(installed.packages()) == 'FALSE') install.packages('Rmisc')
#if ("nlme" %in% rownames(installed.packages()) == 'FALSE') install.packages('nlme')
#if ("lme4" %in% rownames(installed.packages()) == 'FALSE') install.packages('lme4')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("lsmeans" %in% rownames(installed.packages()) == 'FALSE') install.packages('lsmeans')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("reshape" %in% rownames(installed.packages()) == 'FALSE') install.packages('reshape')
if ("multcompView" %in% rownames(installed.packages()) == 'FALSE') install.packages('multcompView')
if ("tidyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('tidyr')
if ("Rcmdr" %in% rownames(installed.packages()) == 'FALSE') install.packages('Rcmdr')
# Load packages and pacage version/date/import/depends info
library(dplyr)          # Version 0.7.6, Packaged: 2018-06-27, Depends: R (>= 3.1.2)Imports: assertthat (>= 0.2.0), bindrcpp (>= 0.2.0.9000), glue (>=1.1.1), magrittr (>= 1.5), methods, pkgconfig (>= 2.0.1), R6(>= 2.2.2), Rcpp (>= 0.12.15), rlang (>= 0.2.0), tibble (>=1.3.1), tidyselect (>= 0.2.3), utils
if ("rlang" %in% rownames(installed.packages()) == 'FALSE') install.packages('rlang')
library(plyr)           # Version 1.8.4, Packaged: 2016-06-07, Depends: R (>= 3.1.0) Imports: Rcpp (>= 0.11.0)
library(ggplot2)        # Version 3.1.0, Date/Publication: 2018-10-25, Depends: R (>= 3.1)Imports: digest, grid, gtable (>= 0.1.1), lazyeval, MASS, mgcv, plyr(>= 1.7.1), reshape2, rlang (>= 0.2.1), scales (>= 0.5.0),stats, tibble, viridisLite, withr (>= 2.0.0)
library(ggpubr)         # Version: 0.1.8 Date: 2018-08-30, Depends: R (>= 3.1.0), ggplot2, magrittrImports: ggrepel, grid, ggsci, stats, utils, tidyr, purrr, dplyr(>=0.7.1), cowplot, ggsignif, scales, gridExtra, glue, polynom
#library(nlme)           # Version: 3.1-137, Date: 2018-04-07, Depends: R (>= 3.4.0) Imports: graphics, stats, utils, lattice
#library(lme4)           # Version: 1.1-17, Date/Publication: 2018-04-03, Depends: R (>= 3.2.0), Matrix (>= 1.2-1), methods, stats
library(plotrix)        # Version: 3.7-4, Date/Publication: 2018-10-03
library(Rmisc)          # Version: 1.5 Packaged: 2013-10-21, Depends: lattice, plyr
library(lsmeans)        # Version: 2.27-62, Date/Publication: 2018-05-11, Depends: methods, R (>= 3.2)
library(gridExtra)      # Version: 2.3, Date/Publication: 2017-09-09, Imports: gtable, grid, grDevices, graphics, utils
library(reshape)        # Version: 0.8.7, Date/Publication: 2017-08-06, Depends: R (>= 2.6.1) Imports: plyr
library(multcompView)   # Version: 0.1-7, Date/Publication: 2015-07-31, Imports: grid
library(Rcmdr)          # Version: 2.5-1. Date/Publication: 2018-09-11, Depends: R (>= 3.5.0), grDevices, graphics, methods, stats, utils,splines, RcmdrMisc (>= 2.5-0), car (>= 3.0-1), effects (>=4.0-3) Imports: tcltk, tcltk2 (>= 1.2-6), abind, relimp (>= 1.0-5)
library(rlang)          # Version: 0.3.0.1 Date/Publication: 2018-10-25, Depends: R (>= 3.1.0)
library(tidyr)          # Version: 0.8.1, Date/Publication: 2018-05-18, Depends: R (>= 3.1) Imports: dplyr (>= 0.7.0), glue, magrittr, purrr, Rcpp, rlang, stringi, tibble, tidyselect
