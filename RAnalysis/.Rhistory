dev.off()
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/Data/Apex_data/Graphs/20190209_Apex_Data_Output.data.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(10, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(6.5, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.201:80/cgi-bin/datalog.xml?sdate=190206&days=3") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
xmlfile <- xmlParse("http://192.168.1.201:80/cgi-bin/datalog.xml?sdate=190217&days=1") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2)
names(Apex.Data2)
xmlfile <- xmlParse("http://192.168.1.201:80/cgi-bin/datalog.xml?sdate=190217&days=1") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","TMP_T1",
"pH_T1", "TMP_T3", "pH_T3", "TMP_T4", "pH_T4", "TMP_T5", "pH_T5",
"TMP_T6", "pH_T6", "TMP_T7", "pH_T7")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/Data/Apex_data/Output/20190217_Apex_Data_Output.data.TEST.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/Data/Apex_data/Graphs/20190217_Apex_Data_Output.data.TEST.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(10, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(6.5, 8.1),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(2, 5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
axis.POSIXct(side=1, Probe.Data$Date.Time)
nd pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/Data/Apex_data/Graphs/20190217_Apex_Data_Output.data.TEST.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(10, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(2, 5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
library("XML")
library("plyr")
xmlfile <- xmlParse("http://192.168.1.200:80/cgi-bin/datalog.xml?sdate=190219&days=1") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
xmlfile <- xmlParse("http://192.168.1.201:80/cgi-bin/datalog.xml?sdate=190219&days=1") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
xmlfile <- xmlParse("http://192.168.1.200:80/cgi-bin/datalog.xml?sdate=190219&days=1") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","TMP_T1",
"pH_T1", "TMP_T3", "pH_T3", "TMP_T4", "pH_T4", "TMP_T5", "pH_T5",
"TMP_T6", "pH_T6", "TMP_T7", "pH_T7")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
Probe.Data
tail(Probe.Data)
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,12,66, 69, 72, 75, 78, 81, 84, 87, 90, 93, 96, 99, 102, 105, 108)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "Sal", "TMP_T2", "pH_T2","TMP_T1",
"pH_T1", "TMP_T3", "pH_T3", "TMP_T4", "pH_T4", "TMP_T5", "pH_T5",
"TMP_T6", "pH_T6", "TMP_T7", "pH_T7")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
tail(Probe.Data)
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,69,72,75,78,81,84,87,90,93,96,99,102,105,108)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "TMP_T4", "pH_T4", "TMP_T6","pH_T6",
"TMP_T5", "pH_T5", "TMP_T1", "pH_T1", "TMP_T7", "pH_T7", "TMP_T3",
"pH_T3", "TMP_T2", "pH_T2")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
tail(Probe.Data)
xmlfile <- xmlParse("http://192.168.1.200:80/cgi-bin/datalog.xml?sdate=190219&days=1") #read in the date plus x days of Apex data
Apex.Data <- ldply(xmlToList(xmlfile), data.frame) #convert xml to dataframe
Apex.Data2 <- Apex.Data[4:nrow(Apex.Data),] #remove extra metadata from top
Apex.Data2 <- head(Apex.Data2,-2) #remove extra metadata from bottom
# view data and names to ID the raw probe.name or probe.type or probe.value
Apex.Data2
tail(Apex.Data2) # check most recent data
names(Apex.Data2)
#keep columnes with data of interest. This needs to be changed as it will be specific to the Apex configuration
Probe.Data <- Apex.Data2[,c(3,6,9,69,72,75,78,81,84,87,90,93,96,99,102,105,108)] #select columns
colnames(Probe.Data) <- c("Date.Time", "TMP_T0", "pH_T0", "TMP_T4", "pH_T4", "TMP_T6","pH_T6",
"TMP_T5", "pH_T5", "TMP_T1", "pH_T1", "TMP_T7", "pH_T7", "TMP_T3",
"pH_T3", "TMP_T2", "pH_T2")  #rename columns
Probe.Data$Date.Time <- as.POSIXct(Probe.Data$Date.Time, format = "%m/%d/%Y %H:%M:%S", tz="HST") #convert date to HI time
tail(Probe.Data)
# tail(Probe.Data) # to view the newest data and compare to APEX fusion for assigning column names
# CHANGE DATE FOR NEW CSV (risk overwritting previous)
write.csv(Probe.Data, "C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/Data/Apex_data/Output/201902120_Apex_Data_Output.data.TEST.csv") #write file to save data
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/Data/Apex_data/Graphs/20190220_Apex_Data_Output.data.TEST.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(10, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(2, 5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
#plot Temp and pH and save to output
# CHANGE DATE FOR NEW PDF (risk overwritting previous)
pdf("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/Data/Apex_data/Graphs/20190220_Apex_Data_Output.data.TEST.pdf")
par(mfrow=c(2,1))
plot(as.numeric(as.character(TMP_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(10, 20),  xlab="Time", ylab="Temperature Â°C")
lines(as.numeric(as.character(TMP_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(TMP_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(TMP_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(TMP_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(TMP_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(TMP_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(TMP_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
plot(as.numeric(as.character(pH_T0)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(3.5, 8.5),  xlab="Time", ylab="pH NBS")
lines(as.numeric(as.character(pH_T1)) ~ Date.Time, Probe.Data, col = "red")
lines(as.numeric(as.character(pH_T2)) ~ Date.Time, Probe.Data, col = "blue")
lines(as.numeric(as.character(pH_T3)) ~ Date.Time, Probe.Data, col = "black")
lines(as.numeric(as.character(pH_T4)) ~ Date.Time, Probe.Data, col = "green")
lines(as.numeric(as.character(pH_T5)) ~ Date.Time, Probe.Data, col = "purple")
lines(as.numeric(as.character(pH_T6)) ~ Date.Time, Probe.Data, col = "orange")
lines(as.numeric(as.character(pH_T7)) ~ Date.Time, Probe.Data, col = "brown")
axis.POSIXct(side=1, Probe.Data$Date.Time)
# plot(as.numeric(as.character(Salt_XL)) ~ Date.Time, Probe.Data, col = "grey", type="l", ylim=c(20, 35),  xlab="Time", ylab="Salinity psu")
# lines(as.numeric(as.character(Salt_L)) ~ Date.Time, Probe.Data, col = "red")
# lines(as.numeric(as.character(Salt_A)) ~ Date.Time, Probe.Data, col = "blue")
# axis.POSIXct(side=1, Probe.Data$Date.Time)
dev.off()
adme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
library(devtools)
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
#Required Data files
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/")
#Load Sample Info
Sample.Info <- read.csv(file="Data/SDR_data/REFERENCE_number.individuals_shell.size.csv", header=T) #read sample.info data
# CHANGE THE FOLLOWING ..THEN CONTROL A + ENTER
# Respiration File
path.p<-"Data/SDR_data/All_resp_data" #the location of all your respirometry files
a <- 0.4
ouputNAME<-"Data/SDR_data/Cumulative_resp_alpha0.4.csv"
# bring in the respiration file names
file.names.full<-basename(list.files(path = path.p, pattern = "csv$", recursive = TRUE)) #list all csv file names in the folder and subfolders
file.names <- file.names.full[c(20:23)] # call the files you want to analyze and rbind to the current cumunaltive file
file.names
#includes treatment, tank, chamber volume, animal size/number etc for normalization
df_total <- data.frame() # start dataframe
resp.table <- data.frame(matrix(nrow = 1, ncol = 7)) # create dataframe to save cumunalitively during for loop
colnames(resp.table)<-c('Date', 'RUN', 'SDR_position', 'Lpc', 'Leq' , 'Lz', 'alpha') # names for comuns in the for loop
for(i in 1:length(file.names)) { # for every file in list start at the first and run this following function
Resp.Data <-read.table(file.path(path.p,file.names[i]), skip = 56, header=T, sep=",", na.string="NA", fill = TRUE, as.is=TRUE, fileEncoding="latin1") #reads in the data files
Resp.Data$Time.Min. <- seq.int(0.017, (nrow(Resp.Data))*0.25, by=0.25) #set time in min
#Resp.Data[Resp.Data[,] == "No Sensor"] <- as.numeric(runif(nrow(Resp.Data), min=0, max=300)) #convert any vials with no data
Resp.Data <- Resp.Data[,2:27] #use only res values - 24 total in the 24 well plate (SDR SensorDish)
for(j in 2:(ncol(Resp.Data)-1)){
model <- rankLocReg(
xall=Resp.Data$Time.Min., yall=as.numeric(Resp.Data[, j]),
alpha=a, method="pc", verbose=TRUE) # run the LoLin script
sum.table<-summary(model)
resp.table$Date <- substr(file.names[i], 1,8) # all files have date in the form of yyyymmdd at the start of each csv name
resp.table$RUN <- substr(file.names[i], 15,15) # assign the run to the number in the title for the trials completed that day
resp.table$SDR_position <- colnames(Resp.Data[j]) # assign the vial position - this will be related to contents (blank or individuals) later in script
resp.table$alpha <- a # set at start of script - reresents the proportion of data for final estimate of slopes (Lpc, Leq, Lz)
resp.table$Lpc <-sum.table$Lcompare[3,6] # Lpc slope
resp.table$Leq <-sum.table$Lcompare[2,6] # Leq slope
resp.table$Lz <-sum.table$Lcompare[1,6]  # Lz slope
#resp.table$ci.Lz<-sum.table$Lcompare[1,9]
#resp.table$ci.Leq<-sum.table$Lcompare[2,9]
#resp.table$ci.Lpc<-sum.table$Lcompare[3,9]
df <- data.frame(resp.table) # name dataframe for this singl e row
df_total <- rbind(df_total,df) #bind to a cumulative list dataframe
print(df_total) # print to monitor progress
# save plots every inside loop and name by date_run_vialposition
pdf(paste0("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/Data/SDR_data/All_resp_data/plots_alpha0.4/",substr(file.names[i], 1,8),"_", "RUN",substr(file.names[i], 15,15),"_",colnames(Resp.Data[j]),"_regression.pdf"))
plot(model)
dev.off()
} # end of inside for loop
} # end of outside for loop
# merge with the preexisiting table?
cumulative_resp_table <- read.csv(file="Data/SDR_data/Cumulative_resp_alpha0.4.csv", header=T) #call the pre exisiting cumulative table
new_table <- rbind(cumulative_resp_table, df_total) # bind the new table from the for loop to the pre exisiting table
write.table(new_table,ouputNAME,sep=",", row.names=FALSE)  # write out to the path names outputNAME
by: Sam Gurr
#Date Last Modified: 20190324
#See Readme file for details
rm(list=ls()) #clears workspace
## install packages if you dont already have them in your library
if ("devtools" %in% rownames(installed.packages()) == 'FALSE') install.packages('devtools')
library(devtools)
if ("segmented" %in% rownames(installed.packages()) == 'FALSE') install.packages('segmented')
if ("plotrix" %in% rownames(installed.packages()) == 'FALSE') install.packages('plotrix')
if ("gridExtra" %in% rownames(installed.packages()) == 'FALSE') install.packages('gridExtra')
if ("LoLinR" %in% rownames(installed.packages()) == 'FALSE') install_github('colin-olito/LoLinR')
if ("lubridate" %in% rownames(installed.packages()) == 'FALSE') install.packages('lubridate')
if ("chron" %in% rownames(installed.packages()) == 'FALSE') install.packages('chron')
if ("plyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('plyr')
if ("dplyr" %in% rownames(installed.packages()) == 'FALSE') install.packages('dplyr')
#Read in required libraries
##### Include Versions of libraries
#install_github('colin-olito/LoLinR')
library("ggplot2")
library("segmented")
library("plotrix")
library("gridExtra")
library("LoLinR")
library("lubridate")
library("chron")
library('plyr')
library('dplyr')
# Set Working Directory:
# setwd("~/MyProjects/Geoduck_Conditioning/RAnalysis/") #set working
setwd("C:/Users/samjg/Documents/My_Projects/Geoduck_transgen_offspring_OA/RAnalysis/")
#Load Sample Info
Sample.Info <- read.csv(file="Data/SDR_data/REFERENCE_number.individuals_shell.size.csv", header=T) #read sample.info data
# X = the cumulative summary table of all Lolin outputs
# (1) merge witht he individual number or size data after you make the cumulative table
#x <- merge(df_total, Sample.Info, by=c("Date","SDR_position", "RUN")) # merge the individual info (size, estimate number of larvae) by common columns
# (2) instead of making this table (renders through many csv files for hours) - open the csv of the finished table itself
# call the cumulative resp table of Lolin raw outputs
cumulative_resp_table <- read.csv(file="Data/SDR_data/Cumulative_resp_alpha0.4.csv", header=T) #read sample.info data
# call the sample info of size and number of individuals per trial ( sample info called above)
x <- merge(cumulative_resp_table, Sample.Info, by=c("Date","SDR_position", "RUN"))
Dhingeresp_190325 <- x %>%
filter((substr(x$Date, 1,9)) == "20190325") # call only resp values of juveniles
Dhingeresp_190325
# Run 1 T0
Dhingeresp_T0 <- Dhingeresp_190325 %>%
filter((Dhingeresp_190325$RUN) == 1)# call only resp values of juveniles
# Run 1 T0
Dhingeresp_T0 <- Dhingeresp_190325 %>%
filter((Dhingeresp_190325$RUN) == 1)# call only resp values of juveniles
Dhingeresp_T0
DhingeT0resp_blanks <- Dhingeresp_190325 %>%  filter(Dhingeresp_190325$Tank.ID == "Blank") # call only blanks
DhingeT0resp_blankMEANS <- DhingeT0resp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
DhingeT0resp_blankMEANS
DhingeT0resp_blanks
DhingeT0resp_blankMEANS
DhingeT0resp_blanks
DhingeT0resp_geoduck <- Dhingeresp_190325 %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
DhingeT0resp_geoduck
DhingeT0resp_blanks <- Dhingeresp_T0 %>%  filter(Dhingeresp_T0$Tank.ID == "Blank") # call only blanks
DhingeT0resp_blankMEANS <- DhingeT0resp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
DhingeT0resp_blanks
DhingeT0resp_blankMEANS
DhingeT0resp_geoduck <- Dhingeresp_T0 %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
DhingeT0resp_geoduck
DhingeT0resp_geoduck$Resp_rate_ug.mol <-
((((((abs(DhingeT0resp_geoduck$Lpc)) - (DhingeT0resp_blankMEANS$mean_Lpc))*(0.08/1000))*(60))*31.998)/(DhingeT0resp_geoduck$length_number.individuals))
DhingeT0resp_geoduck$Resp_rate_ug.mol # units in ug O2/hr/individual
DhingeT0resp_table_treatments_ALL <- DhingeT0resp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
DhingeT0resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
# Run 2 T1 ---------------
Dhingeresp_T1 <- Dhingeresp_190325 %>%
filter((Dhingeresp_190325$RUN) == 2)# call only resp values of juveniles
Dhingeresp_T1
DhingeT1resp_blanks <- Dhingeresp_T1 %>%  filter(Dhingeresp_T1$Tank.ID == "Blank") # call only blanks
DhingeT1resp_blankMEANS <- DhingeT1resp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
DhingeT1resp_blanks
DhingeT1resp_blankMEANS
DhingeT1resp_geoduck <- Dhingeresp_T1 %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
DhingeT1resp_geoduck
DhingeT1resp_geoduck$Resp_rate_ug.mol <-
((((((abs(DhingeT1resp_geoduck$Lpc)) - (DhingeT1resp_blankMEANS$mean_Lpc))*(0.08/1000))*(60))*31.998)/(DhingeT1resp_geoduck$length_number.individuals))
DhingeT1resp_geoduck$Resp_rate_ug.mol # units in ug O2/hr/individual
DhingeT1resp_table_treatments_ALL <- DhingeT1resp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
DhingeT1resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
# Run 3 T2 ---------------
Dhingeresp_T3 <- Dhingeresp_190325 %>%
filter((Dhingeresp_190325$RUN) == 3)# call only resp values of juveniles
DhingeT3resp_blanks <- Dhingeresp_T3 %>%  filter(Dhingeresp_T3$Tank.ID == "Blank") # call only blanks
DhingeT3resp_blankMEANS <- DhingeT3resp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
DhingeT3resp_blanks
DhingeT3resp_geoduck <- Dhingeresp_T3 %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
DhingeT3resp_geoduck
DhingeT3resp_geoduck$Resp_rate_ug.mol <-
((((((abs(DhingeT3resp_geoduck$Lpc)) - (DhingeT3resp_blankMEANS$mean_Lpc))*(0.08/1000))*(60))*31.998)/(DhingeT3resp_geoduck$length_number.individuals))
DhingeT3resp_geoduck$Resp_rate_ug.mol # units in ug O2/hr/individual
DhingeT3resp_table_treatments_ALL <- DhingeT3resp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
DhingeT3resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
DhingeT3resp_geoduck$Resp_rate_ug.mol # units in ug O2/hr/individual
# Run 3 T2 ---------------
Dhingeresp_T2 <- Dhingeresp_190325 %>%
filter((Dhingeresp_190325$RUN) == 3)# call only resp values of juveniles
DhingeT2resp_blanks <- Dhingeresp_T2 %>%  filter(Dhingeresp_T2$Tank.ID == "Blank") # call only blanks
DhingeT2resp_blankMEANS <- DhingeT2resp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
DhingeT2resp_geoduck <- Dhingeresp_T2 %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
DhingeT2resp_geoduck$Resp_rate_ug.mol <-
((((((abs(DhingeT2resp_geoduck$Lpc)) - (DhingeT2resp_blankMEANS$mean_Lpc))*(0.08/1000))*(60))*31.998)/(DhingeT2resp_geoduck$length_number.individuals))
DhingeT2resp_geoduck$Resp_rate_ug.mol # units in ug O2/hr/individual
DhingeT2resp_table_treatments_ALL <- DhingeT2resp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
DhingeT2resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
DhingeT2resp_geoduck$Resp_rate_ug.mol # units in ug O2/hr/individual
DhingeT2resp_blanks <- Dhingeresp_T2 %>%  filter(Dhingeresp_T2$Tank.ID == "Blank") # call only blanks
DhingeT2resp_blankMEANS <- DhingeT2resp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
# Run 4 T3 ---------------
Dhingeresp_T3 <- Dhingeresp_190325 %>%
filter((Dhingeresp_190325$RUN) == 4)# call only resp values of juveniles
DhingeT3resp_blanks <- Dhingeresp_T3 %>%  filter(Dhingeresp_T3$Tank.ID == "Blank") # call only blanks
DhingeT3resp_blankMEANS <- DhingeT3resp_blanks %>%
summarise(mean_Lpc = mean(abs(Lpc)),mean_Leq = mean(abs(Leq)), mean_Lz = mean(abs(Lz))) # summarize the blanks into a mean value
DhingeT3resp_geoduck <- Dhingeresp_T3 %>%
filter(!is.na(length_number.individuals)) # remove the NAs from the number of individuals (these are the blanks)
DhingeT3resp_geoduck
DhingeT3resp_geoduck$Resp_rate_ug.mol <-
((((((abs(DhingeT3resp_geoduck$Lpc)) - (DhingeT3resp_blankMEANS$mean_Lpc))*(0.08/1000))*(60))*31.998)/(DhingeT3resp_geoduck$length_number.individuals))
DhingeT3resp_geoduck$Resp_rate_ug.mol # units in ug O2/hr/individual
DhingeT3resp_table_treatments_ALL <- DhingeT3resp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
DhingeT3resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
DhingeT3resp_geoduck$Resp_rate_ug.mol # units in ug O2/hr/individual
DhingeT3resp_table_treatments_ALL <- DhingeT3resp_geoduck %>%
group_by(Treatment) %>% #group the dataset by BOTH INITIAL AND SECONDARY TREATMENT
summarise(mean_resp = mean(Resp_rate_ug.mol),
max_resp = max(Resp_rate_ug.mol),
min_resp = min(Resp_rate_ug.mol),
sd_resp = sd(Resp_rate_ug.mol),
SEM = ((sd(Resp_rate_ug.mol))/sqrt(n())),
count =n()) %>% # get the count by leaving n open
arrange(desc(min_resp)) # makes table in descending order
DhingeT3resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
DhingeT0resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
DhingeT1resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
DhingeT2resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
DhingeT3resp_table_treatments_ALL # view table - looks like the LARVAE resp was no different from the blanks
